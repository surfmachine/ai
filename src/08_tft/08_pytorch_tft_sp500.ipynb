{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabe 08 - Temporal Fusion Transformer with SP 500\n",
    "01.01.2022, Thomas Iten\n",
    "\n",
    "**Content**\n",
    "1. **Load data (with SP500 data module slightly adapted for time series support)**\n",
    "2. Extact feature columns\n",
    "3. Create TimeSeriesDataSet\n",
    "4. **Create baseline model and train**\n",
    "5. Train the Temporal Fusion Transformer\n",
    "6. Train the model\n",
    "7. Evaluate model performance with validation data\n",
    "8. **Evaluate model performance with test data**\n",
    "\n",
    "**References**\n",
    "- https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/stallion.html\n",
    "- https://www.kaggle.com/utathya/future-volume-prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#\n",
    "# Imports\n",
    "#\n",
    "\n",
    "import os, os.path, requests, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import yfinance\n",
    "import warnings\n",
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "import datetime\n",
    "#from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting.models.rnn import RecurrentNetwork\n",
    "\n",
    "#\n",
    "# Settings\n",
    "#\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "warnings.filterwarnings(\"ignore\")                       # avoid printing out absolute paths\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load data (with SP500 data module slightly adapted for time series support)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define data loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class SP500DataModule(pl.LightningDataModule):\n",
    "    \"\"\"Data module for the 'Standard and Poor 500' company performance data, adapted for time series support.\n",
    "\n",
    "    NOTE:\n",
    "    To support the TFT task, the time_series flag has be introduced. By enabling this option,\n",
    "    the data will be enhanced with the a time index and group flag, to support the TimeSeriesDataSet format.\n",
    "    \"\"\"\n",
    "\n",
    "    URL = \"http://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size=32,\n",
    "                 train_val_test_split=[80,10,10],\n",
    "                 spy_binary=True,\n",
    "                 time_series=False,\n",
    "                 path=\".\",\n",
    "                 force_download=False):\n",
    "        super().__init__()\n",
    "        # download properties\n",
    "        self.start = datetime.datetime(2010, 1, 1)\n",
    "        self.end = datetime.datetime.now()\n",
    "        self.fname = path + \"/sp500.csv\"\n",
    "        self.force_download = force_download\n",
    "        # prepare and transform properties\n",
    "        self.spy_binary = spy_binary\n",
    "        self.time_series = time_series\n",
    "        self.batch_size = batch_size\n",
    "        self.train_val_test_split = train_val_test_split\n",
    "        # data\n",
    "        self.data = None\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Download and prepare the SP500 data.\"\"\"\n",
    "        df = self._download_sp500()\n",
    "        if self.spy_binary:\n",
    "            df.SPY = [1 if spy > 0 else 0 for spy in df.SPY]\n",
    "        self.data = df\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Setup the data according the stage 'fit' or 'test'. If the stage is none, setup the data for all stages.\"\"\"\n",
    "\n",
    "        # Split data into test, val and train dataframes\n",
    "        train_percent, val_percent, test_percent = self.train_val_test_split\n",
    "        rows = self.data.shape[0]\n",
    "        test_rows = int(test_percent * rows / 100)\n",
    "        val_rows = int(val_percent * rows / 100)\n",
    "        train_rows =  rows - test_rows - val_rows\n",
    "\n",
    "        print(\"Setup - define data split:\")\n",
    "        print(\"- Train rows : {0:04d} ( {1}%)\".format(train_rows, train_percent))\n",
    "        print(\"- Val   rows : {0:04d} ( {1}%)\".format(val_rows, val_percent))\n",
    "        print(\"- Test  rows : {0:04d} ( {1}%)\".format(test_rows, test_percent))\n",
    "        print(\"- Total rows : {0:04d} (100%)\".format(rows))\n",
    "\n",
    "        print(\"Setup - split and transform data for stage: {}\".format(stage))\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_data = self.data.iloc[:train_rows]\n",
    "            val_data = self.data.iloc[train_rows:train_rows+val_rows]\n",
    "            print(\"- Train shape: {}\".format(train_data.shape))\n",
    "            print(\"- Val   shape: {}\".format(val_data.shape))\n",
    "            # transform data and assign properties to use in data loaders\n",
    "            self.train_dataset = self._transform(train_data)\n",
    "            self.val_dataset = self._transform(val_data)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            test_data = self.data.iloc[train_rows+val_rows:]\n",
    "            print(\"- Test  shape: {}\".format(test_data.shape))\n",
    "            # transform data and assign properties to use in data loaders\n",
    "            self.test_dataset = self._transform(test_data)\n",
    "        print(\"- Total shape: {}\".format(self.data.shape))\n",
    "\n",
    "\n",
    "    def size(self):\n",
    "        return self.train_dataloader().dataset.tensors[0].data.shape[1]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def _transform(self, df):\n",
    "        if self.time_series:\n",
    "            return self._transform_to_timeseries_df(df)\n",
    "        return self._transform_to_dataset(df)\n",
    "\n",
    "    def _transform_to_timeseries_df(self, df):\n",
    "        # create time index\n",
    "        df['date'] = df.index.to_pydatetime()\n",
    "        df[\"time_idx\"] = df[\"date\"].dt.year * 12 * 31 + df[\"date\"].dt.month * 31 + df[\"date\"].dt.day\n",
    "        df[\"time_idx\"] -= int(df[\"time_idx\"].min())\n",
    "        # create group (At least one groupt is used for the TimeSeriesDataSet)\n",
    "        df['group_id'] = 0\n",
    "        # return result\n",
    "        return df\n",
    "\n",
    "    def _transform_to_dataset(self, df):\n",
    "        # Split labels and features\n",
    "        labels = df.SPY.values\n",
    "        features = df.iloc[:, :-1].values\n",
    "        # Convert to tensor\n",
    "        tensor_labels   = torch.tensor(labels).unsqueeze(1).float()\n",
    "        tensor_features = torch.tensor(features).float()\n",
    "        # Create tensor dataset\n",
    "        return TensorDataset(tensor_features, tensor_labels)\n",
    "\n",
    "    def _download_sp500(self) -> pd.DataFrame:\n",
    "        \"\"\"Download the SP500 data from the internet, save data to a csv file and return the result.\n",
    "\n",
    "        Notes:\n",
    "        - All further calls will serve the data from the csv file.\n",
    "        - To trigger a new download from the internet, set the force_download flag to True.\n",
    "        \"\"\"\n",
    "\n",
    "        # Load data from file\n",
    "        if os.path.isfile(self.fname) and not self.force_download:\n",
    "            print(\"Load SP500 from file:\", self.fname)\n",
    "            return pd.read_csv(self.fname, index_col=0, parse_dates=True)\n",
    "\n",
    "        # Download data\n",
    "        print(\"Download data from:\", SP500DataModule.URL)\n",
    "        resp = requests.get(SP500DataModule.URL)\n",
    "        soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "        table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "\n",
    "        tickers = []\n",
    "        for row in table.findAll('tr')[1:]:\n",
    "            ticker = row.findAll('td')[0].text\n",
    "            tickers.append(ticker)\n",
    "\n",
    "        tickers = [s.replace('\\n', '') for s in tickers]\n",
    "        data = yfinance.download(tickers, start=self.start, end=self.end)\n",
    "        df_data = data['Adj Close']\n",
    "\n",
    "        df_spy = yfinance.download(\"SPY\", start=self.start, end=self.end)\n",
    "        df_spy = df_spy.loc[:, ['Adj Close']]\n",
    "        df_spy.columns = ['SPY']\n",
    "\n",
    "        df = pd.concat([df_data, df_spy], axis=1)\n",
    "\n",
    "        # Prepare data\n",
    "        df.dropna(axis=0, how='all', inplace=True)\n",
    "        print(\"Dropping columns due to nans > 50%:\", df.loc[:, list((100 * (df.isnull().sum() / len(df.index)) > 50))].columns)\n",
    "        df = df.drop(df.loc[:, list((100 * (df.isnull().sum() / len(df.index)) > 50))].columns, 1)\n",
    "        df = df.ffill().bfill()\n",
    "        print(\"Any columns still contain nans:\", df.isnull().values.any())\n",
    "\n",
    "        df_returns = pd.DataFrame()\n",
    "        for name in df.columns:\n",
    "            df_returns[name] = np.log(df[name]).diff()\n",
    "\n",
    "        df_returns.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "        # Save data and return result\n",
    "        print(\"Save data to file:\", self.fname)\n",
    "        df_returns.to_csv(self.fname)\n",
    "\n",
    "        self.data = df_returns\n",
    "        return self.data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load SP500 from file: ./sp500.csv\n",
      "Setup - define data split:\n",
      "- Train rows : 2392 ( 80%)\n",
      "- Val   rows : 0299 ( 10%)\n",
      "- Test  rows : 0299 ( 10%)\n",
      "- Total rows : 2990 (100%)\n",
      "Setup - split and transform data for stage: None\n",
      "- Train shape: (2392, 490)\n",
      "- Val   shape: (299, 490)\n",
      "- Test  shape: (299, 490)\n",
      "- Total shape: (2990, 490)\n",
      "Data Type:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Data\n"
     ]
    },
    {
     "data": {
      "text/plain": "                   A       AAL       AAP      AAPL  ABBV       ABC      ABMD  \\\nDate                                                                           \n2010-01-04  0.007375 -0.014569 -0.002473  0.015445   0.0  0.021253  0.001145   \n2010-01-05 -0.010922  0.107246 -0.005962  0.001727   0.0 -0.007160 -0.024321   \n2010-01-06 -0.003559 -0.042314  0.008682 -0.016034   0.0 -0.009501 -0.015358   \n2010-01-07 -0.001297  0.029044 -0.000247 -0.001850   0.0 -0.016166  0.000000   \n2010-01-08 -0.000325 -0.019268  0.003945  0.006626   0.0  0.010807 -0.020446   \n\n                 ABT       ACN      ADBE  ...  XYL       YUM       ZBH  \\\nDate                                      ...                            \n2010-01-04  0.008668  0.013641  0.008393  ...  0.0  0.003426  0.015278   \n2010-01-05 -0.008112  0.006162  0.016313  ...  0.0 -0.003426  0.031165   \n2010-01-06  0.005539  0.010574 -0.002124  ...  0.0 -0.007174 -0.000323   \n2010-01-07  0.008250 -0.000935 -0.019595  ...  0.0 -0.000288  0.022681   \n2010-01-08  0.005099 -0.003986 -0.005436  ...  0.0  0.000288 -0.021228   \n\n                ZBRA      ZION  ZTS       SPY       date  time_idx  group_id  \nDate                                                                          \n2010-01-04  0.011224  0.038231  0.0  0.016817 2010-01-04         0         0  \n2010-01-05 -0.001745  0.034651  0.0  0.002644 2010-01-05         1         0  \n2010-01-06 -0.007717  0.083382  0.0  0.000704 2010-01-06         2         0  \n2010-01-07 -0.025318  0.106160  0.0  0.004212 2010-01-07         3         0  \n2010-01-08 -0.003256 -0.016320  0.0  0.003322 2010-01-08         4         0  \n\n[5 rows x 493 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>AAL</th>\n      <th>AAP</th>\n      <th>AAPL</th>\n      <th>ABBV</th>\n      <th>ABC</th>\n      <th>ABMD</th>\n      <th>ABT</th>\n      <th>ACN</th>\n      <th>ADBE</th>\n      <th>...</th>\n      <th>XYL</th>\n      <th>YUM</th>\n      <th>ZBH</th>\n      <th>ZBRA</th>\n      <th>ZION</th>\n      <th>ZTS</th>\n      <th>SPY</th>\n      <th>date</th>\n      <th>time_idx</th>\n      <th>group_id</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2010-01-04</th>\n      <td>0.007375</td>\n      <td>-0.014569</td>\n      <td>-0.002473</td>\n      <td>0.015445</td>\n      <td>0.0</td>\n      <td>0.021253</td>\n      <td>0.001145</td>\n      <td>0.008668</td>\n      <td>0.013641</td>\n      <td>0.008393</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.003426</td>\n      <td>0.015278</td>\n      <td>0.011224</td>\n      <td>0.038231</td>\n      <td>0.0</td>\n      <td>0.016817</td>\n      <td>2010-01-04</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2010-01-05</th>\n      <td>-0.010922</td>\n      <td>0.107246</td>\n      <td>-0.005962</td>\n      <td>0.001727</td>\n      <td>0.0</td>\n      <td>-0.007160</td>\n      <td>-0.024321</td>\n      <td>-0.008112</td>\n      <td>0.006162</td>\n      <td>0.016313</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.003426</td>\n      <td>0.031165</td>\n      <td>-0.001745</td>\n      <td>0.034651</td>\n      <td>0.0</td>\n      <td>0.002644</td>\n      <td>2010-01-05</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2010-01-06</th>\n      <td>-0.003559</td>\n      <td>-0.042314</td>\n      <td>0.008682</td>\n      <td>-0.016034</td>\n      <td>0.0</td>\n      <td>-0.009501</td>\n      <td>-0.015358</td>\n      <td>0.005539</td>\n      <td>0.010574</td>\n      <td>-0.002124</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.007174</td>\n      <td>-0.000323</td>\n      <td>-0.007717</td>\n      <td>0.083382</td>\n      <td>0.0</td>\n      <td>0.000704</td>\n      <td>2010-01-06</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2010-01-07</th>\n      <td>-0.001297</td>\n      <td>0.029044</td>\n      <td>-0.000247</td>\n      <td>-0.001850</td>\n      <td>0.0</td>\n      <td>-0.016166</td>\n      <td>0.000000</td>\n      <td>0.008250</td>\n      <td>-0.000935</td>\n      <td>-0.019595</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.000288</td>\n      <td>0.022681</td>\n      <td>-0.025318</td>\n      <td>0.106160</td>\n      <td>0.0</td>\n      <td>0.004212</td>\n      <td>2010-01-07</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2010-01-08</th>\n      <td>-0.000325</td>\n      <td>-0.019268</td>\n      <td>0.003945</td>\n      <td>0.006626</td>\n      <td>0.0</td>\n      <td>0.010807</td>\n      <td>-0.020446</td>\n      <td>0.005099</td>\n      <td>-0.003986</td>\n      <td>-0.005436</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000288</td>\n      <td>-0.021228</td>\n      <td>-0.003256</td>\n      <td>-0.016320</td>\n      <td>0.0</td>\n      <td>0.003322</td>\n      <td>2010-01-08</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 493 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = SP500DataModule(spy_binary=False, time_series=True)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "data = dm.train_dataset\n",
    "\n",
    "print(\"Data Type:\")\n",
    "print(type(data))\n",
    "\n",
    "print(\"Data\")\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Extact feature columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABMD', 'ABT', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES', 'AFL', 'AIG', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALGN', 'ALK', 'ALL', 'ALLE', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMGN', 'AMP', 'AMT', 'AMZN', 'ANET', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'APD', 'APH', 'APTV', 'ARE', 'ATO', 'ATVI', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXP', 'AZO', 'BA', 'BAC', 'BAX', 'BBWI', 'BBY', 'BDX', 'BEN', 'BIIB', 'BIO', 'BK', 'BKNG', 'BKR', 'BLK', 'BLL', 'BMY', 'BR', 'BRO', 'BSX', 'BWA', 'BXP', 'C', 'CAG', 'CAH', 'CAT', 'CB', 'CBOE', 'CBRE', 'CCI', 'CCL', 'CDNS', 'CDW', 'CE', 'CERN', 'CF', 'CFG', 'CHD', 'CHRW', 'CHTR', 'CI', 'CINF', 'CL', 'CLX', 'CMA', 'CMCSA', 'CME', 'CMG', 'CMI', 'CMS', 'CNC', 'CNP', 'COF', 'COO', 'COP', 'COST', 'CPB', 'CPRT', 'CRL', 'CRM', 'CSCO', 'CSX', 'CTAS', 'CTLT', 'CTRA', 'CTSH', 'CTXS', 'CVS', 'CVX', 'CZR', 'D', 'DAL', 'DD', 'DE', 'DFS', 'DG', 'DGX', 'DHI', 'DHR', 'DIS', 'DISCA', 'DISCK', 'DISH', 'DLR', 'DLTR', 'DOV', 'DPZ', 'DRE', 'DRI', 'DTE', 'DUK', 'DVA', 'DVN', 'DXC', 'DXCM', 'EA', 'EBAY', 'ECL', 'ED', 'EFX', 'EIX', 'EL', 'EMN', 'EMR', 'ENPH', 'EOG', 'EQIX', 'EQR', 'ES', 'ESS', 'ETN', 'ETR', 'ETSY', 'EVRG', 'EW', 'EXC', 'EXPD', 'EXPE', 'EXR', 'F', 'FANG', 'FAST', 'FB', 'FBHS', 'FCX', 'FDX', 'FE', 'FFIV', 'FIS', 'FISV', 'FITB', 'FLT', 'FMC', 'FRC', 'FRT', 'FTNT', 'GD', 'GE', 'GILD', 'GIS', 'GL', 'GLW', 'GM', 'GNRC', 'GOOG', 'GOOGL', 'GPC', 'GPN', 'GPS', 'GRMN', 'GS', 'GWW', 'HAL', 'HAS', 'HBAN', 'HBI', 'HCA', 'HD', 'HES', 'HIG', 'HII', 'HLT', 'HOLX', 'HON', 'HPE', 'HPQ', 'HRL', 'HSIC', 'HST', 'HSY', 'HUM', 'IBM', 'ICE', 'IDXX', 'IEX', 'IFF', 'ILMN', 'INCY', 'INFO', 'INTC', 'INTU', 'IP', 'IPG', 'IPGP', 'IQV', 'IRM', 'ISRG', 'IT', 'ITW', 'IVZ', 'J', 'JBHT', 'JCI', 'JKHY', 'JNJ', 'JNPR', 'JPM', 'K', 'KEY', 'KEYS', 'KHC', 'KIM', 'KLAC', 'KMB', 'KMI', 'KMX', 'KO', 'KR', 'KSU', 'L', 'LDOS', 'LEG', 'LEN', 'LH', 'LHX', 'LIN', 'LKQ', 'LLY', 'LMT', 'LNC', 'LNT', 'LOW', 'LRCX', 'LUMN', 'LUV', 'LVS', 'LYB', 'LYV', 'MA', 'MAA', 'MAR', 'MAS', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'MGM', 'MHK', 'MKC', 'MKTX', 'MLM', 'MMC', 'MMM', 'MNST', 'MO', 'MOS', 'MPC', 'MPWR', 'MRK', 'MRO', 'MS', 'MSCI', 'MSFT', 'MSI', 'MTB', 'MTCH', 'MTD', 'MU', 'NCLH', 'NDAQ', 'NEE', 'NEM', 'NFLX', 'NI', 'NKE', 'NLOK', 'NLSN', 'NOC', 'NOW', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NVR', 'NWL', 'NWS', 'NWSA', 'NXPI', 'O', 'ODFL', 'OKE', 'OMC', 'ORCL', 'ORLY', 'OXY', 'PAYC', 'PAYX', 'PBCT', 'PCAR', 'PEAK', 'PEG', 'PENN', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKG', 'PKI', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'POOL', 'PPG', 'PPL', 'PRU', 'PSA', 'PSX', 'PTC', 'PVH', 'PWR', 'PXD', 'PYPL', 'QCOM', 'QRVO', 'RCL', 'RE', 'REG', 'REGN', 'RF', 'RHI', 'RJF', 'RL', 'RMD', 'ROK', 'ROL', 'ROP', 'ROST', 'RSG', 'RTX', 'SBAC', 'SBUX', 'SCHW', 'SEE', 'SHW', 'SIVB', 'SJM', 'SLB', 'SNA', 'SNPS', 'SO', 'SPG', 'SPGI', 'SRE', 'STE', 'STT', 'STX', 'STZ', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYY', 'T', 'TAP', 'TDG', 'TDY', 'TECH', 'TEL', 'TER', 'TFC', 'TFX', 'TGT', 'TJX', 'TMO', 'TMUS', 'TPR', 'TRMB', 'TROW', 'TRV', 'TSCO', 'TSLA', 'TSN', 'TT', 'TTWO', 'TWTR', 'TXN', 'TXT', 'TYL', 'UAA', 'UAL', 'UDR', 'UHS', 'ULTA', 'UNH', 'UNP', 'UPS', 'URI', 'USB', 'V', 'VFC', 'VIAC', 'VLO', 'VMC', 'VNO', 'VRSK', 'VRSN', 'VRTX', 'VTR', 'VTRS', 'VZ', 'WAB', 'WAT', 'WBA', 'WDC', 'WEC', 'WELL', 'WFC', 'WHR', 'WLTW', 'WM', 'WMB', 'WMT', 'WRB', 'WRK', 'WST', 'WU', 'WY', 'WYNN', 'XEL', 'XLNX', 'XOM', 'XRAY', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZION', 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "features_columns = list(data.columns.values[:-4])\n",
    "print(features_columns, sep=\"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Create TimeSeriesDataSet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Max. number of timesteps for prediction\n",
    "max_prediction_length = 6\n",
    "\n",
    "# Max. number of timesteps for training\n",
    "max_encoder_length    = 24\n",
    "\n",
    "# Training cutoff: total - perdiction,\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "def create_time_series_data_set(data):\n",
    "    return TimeSeriesDataSet(\n",
    "        data[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",                            # Zeit Index\n",
    "        group_ids=[\"group_id\"],\n",
    "        target=\"SPY\",\n",
    "        # group_ids=[\"agency\", \"sku\"],                  # Preprocessing: Normaliserung und Encoding je Gruppe.\n",
    "                                                    # Es kann variert werden zwischen min und max\n",
    "        min_encoder_length=max_encoder_length // 2,     # Keep encoder length long (as it is in the validation set)\n",
    "        max_encoder_length=max_encoder_length,          #\n",
    "\n",
    "        min_prediction_length=1,                        # Er kann auch weniger TimeSteps prediction, wenn zu wenig Daten vorhanden sind\n",
    "        max_prediction_length=max_prediction_length,\n",
    "\n",
    "        # statics\n",
    "        # static_categoricals=[\"agency\", \"sku\"],\n",
    "        # static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "\n",
    "        # time varying known (Planwerte) (es wird ein LSTM je Kategorie gebaut und verwendet)\n",
    "        # time_varying_known_categoricals=[\"special_days\", \"month\"],  # known (Plan Werte)\n",
    "        # variable_groups={\"special_days\": special_days},             # group of categorical variables can be treated as one variable\n",
    "\n",
    "        # time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "        time_varying_known_reals=[\"time_idx\"],\n",
    "\n",
    "        # time varying unknown (es wird ein LSTM je Kategorie gebaut und verwendet)\n",
    "        time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=features_columns,\n",
    "\n",
    "        # target_normalizer=GroupNormalizer(                          # TODO ti: auskommentiern wenn log target verwendet wird\n",
    "        #     groups=[\"agency\", \"sku\"], transformation=\"softplus\"     # Use softplus and normalize by group\n",
    "        # ),                                                          # Normalisieurung 8 -> 1,22 zurück 8.5 != exp(8)\n",
    "\n",
    "        # variablen die zusätzlich erstellt werden durch netzwerk\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "        allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "training = create_time_series_data_set(data)\n",
    "\n",
    "# Create validation set (predict=True)\n",
    "# Which means to predict the last max_prediction_length points in time for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "\n",
    "# create data loaders\n",
    "train_dataloader = training.to_dataloader  (train=True,  batch_size=batch_size, num_workers=0)\n",
    "val_dataloader   = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To learn more about the :py:class:`~pytorch_forecasting.data.timeseries.TimeSeriesDataSet`, visit its documentation or the :ref:`tutorial explaining how to pass datasets to models <passing-data>`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Create baseline model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0.003061520168557763"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Train the Temporal Fusion Transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find optimal learning rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prior to training, you can identify the optimal learning rate with the [PyTorch Lightning learning rate finder](https://pytorch-lightning.readthedocs.io/en/latest/lr_finder.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 358.9k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,            # Guter Bereich: 0.01 ... 0.03 / RangerOptimzer ist Top\n",
    "    hidden_size=16,                # most important hyperparameter apart from learning rate\n",
    "    attention_head_size=1,         # number of attention heads. Set to up to 4 for large datasets\n",
    "    dropout=0.1,                   # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,      # set to <= hidden_size\n",
    "    output_size=7,                 # 7 quantiles by default\n",
    "    loss=QuantileLoss(),           # Quantile loss für quantile predictions\n",
    "    reduce_on_plateau_patience=4,  # reduce learning rate if no improvement in validation loss after x epochs\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d677b047e1fb49f695885216c7f640ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at D:\\dev\\workspace\\surfmachine\\ai\\src\\08_tft\\lr_find_temp_model_342839e7-3f72-4c19-b5b9-e16487619cb9.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.07943282347242808\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 358.9k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=1e-4,\n",
    "    patience=10,            # Abbruch wenn 10x nicht verbessert\n",
    "    verbose=False,\n",
    "    mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1, # 30\n",
    "    gpus=0,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # !! Zeigt Feature Importance und weiteres! comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training takes a couple of minutes on my Macbook but for larger networks and datasets, it can take hours. The training speed is here mostly determined by overhead and choosing a larger `batch_size` or `hidden_size` (i.e. network size) does not slow does training linearly making training on large datasets feasible. During training, we can monitor the tensorboard which can be spun up with `tensorboard --logdir=lightning_logs`. For example, we can monitor examples predictions on the training and validation set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0     \n",
      "3  | prescalers                         | ModuleDict                      | 7.9 K \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.7 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 341 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.2 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "358 K     Trainable params\n",
      "0         Non-trainable params\n",
      "358 K     Total params\n",
      "1.435     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e61250f2f53455db665cd8f1c9be6fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "509f15a8aa474c45b2bb94f836289c27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dad50bf85fb74b7a95eca29280beee86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Hyperparamter tuning with [optuna](https://optuna.org/) is directly build into pytorch-forecasting. For example, we can use the \n",
    ":py:func:`~pytorch_forecasting.models.temporal_fusion_transformer.tuning.optimize_hyperparameters` function to optimize the TFT's hyperparameters.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "    import pickle\n",
    "    \n",
    "    from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "    # create study\n",
    "    study = optimize_hyperparameters(\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        model_path=\"optuna_test\",\n",
    "        n_trials=200,\n",
    "        max_epochs=50,\n",
    "        gradient_clip_val_range=(0.01, 1.0),\n",
    "        hidden_size_range=(8, 128),\n",
    "        hidden_continuous_size_range=(8, 128),\n",
    "        attention_head_size_range=(1, 4),\n",
    "        learning_rate_range=(0.001, 0.1),\n",
    "        dropout_range=(0.1, 0.3),\n",
    "        trainer_kwargs=dict(limit_train_batches=30),\n",
    "        reduce_on_plateau_patience=4,\n",
    "        use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    "    )\n",
    "\n",
    "    # save study results - also we can resume tuning at a later point in time\n",
    "    with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "        pickle.dump(study, fout)\n",
    "\n",
    "    # show best hyperparameters\n",
    "    print(study.best_trial.params)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Evaluate model performance with validation data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load best tft\n",
    "PyTorch Lightning automatically checkpoints training and thus, we can easily retrieve the best model and load it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calcualte mean absolute error on validation set\n",
    "\n",
    "After training, we can make predictions with :py:meth:`~pytorch_forecasting.models.base_model.BaseModel.predict`.\n",
    "- The method allows very fine-grained control over what it returns so that, for example, you can easily match\n",
    "  predictions to your pandas dataframe.\n",
    "- See its documentation for details."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0067)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Evaluate model performance with test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create test data loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "test_data = dm.test_dataset\n",
    "ts = create_time_series_data_set(test_data)\n",
    "test = TimeSeriesDataSet.from_dataset(ts, test_data, predict=True, stop_randomization=True)\n",
    "test_dataloader  = test.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calcualte mean absolute error on test set\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0056)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = torch.cat([y[0] for x, y in iter(test_dataloader)])\n",
    "predictions = best_tft.predict(test_dataloader)\n",
    "(actuals - predictions).abs().mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_The end._"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ec18b53a",
   "language": "python",
   "display_name": "PyCharm (python-work)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "colab": {
   "name": "stallion.ipynb",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}